# Project 01 â€” Linear Regression from Scratch

## Goal
Implement linear regression in **two ways** and compare them:

1. **Closed-form least squares** (normal equation / `lstsq`)
2. **Gradient descent** (derive gradients, implement loop)

This project connects directly to:
- projections
- least squares
- dot products
- matrix multiplication

## Dataset
A synthetic dataset: `y = 3x - 2 + noise`.

## Success Criteria
- Your least squares solution predicts close to the true line.
- Your gradient descent converges to similar parameters.
- You can plot data + fitted line + loss curve.

## Stretch Goals
- Add L2 regularization (ridge) and observe coefficients.
- Add feature scaling and show faster convergence.
