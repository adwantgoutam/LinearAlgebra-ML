# Mini Projects (Linear Algebra â†’ ML / Deep Learning)

These mini-projects are designed to **apply linear algebra concepts** in a way that feels like real ML work.
Each project has:
- a short brief
- success criteria
- a starter script you can extend
- optional stretch goals

Recommended order:
1) Linear Regression from scratch (least squares + gradient descent)
2) PCA for compression + reconstruction
3) Cosine similarity "mini search engine" for embeddings
4) Tiny Neural Net (one hidden layer) with vectorized forward pass
5) Self-Attention (QK^T softmax V) demo
6) Sinusoidal Positional Encoding
7) Low-rank update (LoRA intuition)

---

## How to run
From repo root (with venv activated):

```bash
python projects/01_linear_regression_from_scratch/main.py
python projects/02_pca_compression/main.py
python projects/03_embedding_similarity_search/main.py
python projects/04_tiny_dense_layer_nn/main.py
python projects/05_self_attention_demo/main.py
python projects/06_positional_encoding/main.py
python projects/07_low_rank_update_lora_intuition/main.py
```
